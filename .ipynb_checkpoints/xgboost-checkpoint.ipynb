{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "#https://xgboost.readthedocs.io/en/latest/python/index.html\n",
    "# https://github.com/dmlc/xgboost/blob/master/demo/multiclass_classification/train.py#L35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtree.ipynb                t10k-labels-idx1-ubyte.gz\r\n",
      "RF.ipynb                   train-images-idx3-ubyte.gz\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m                train-labels-idx1-ubyte.gz\r\n",
      "load_mnist.py              xgboost.ipynb\r\n",
      "t10k-images-idx3-ubyte.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_mnist import load_mnist\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "train_data, train_label = load_mnist(\"\",\"train\")\n",
    "test_data,test_label = load_mnist(\"\",\"t10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\python\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "d:\\python\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "d:\\python\\lib\\site-packages\\sklearn\\utils\\validation.py:590: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sc = StandardScaler()\n",
    "X_main_std = sc.fit(train_data)\n",
    "\n",
    "train_data = X_main_std.transform(train_data)\n",
    "test_data = X_main_std.transform(test_data)\n",
    "\n",
    "\n",
    "# min_max_scaler=preprocessing.MinMaxScaler()  \n",
    "# min_max=min_max_scaler.fit(train_data)\n",
    "\n",
    "# train_data = min_max.transform(train_data)\n",
    "# test_data = min_max.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'multi:softmax', 'eta': 0.3, 'num_class': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'merror', 'silent': 1, 'tree_method': 'exact', 'max_depth': 15}\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# num_round = [2,10,50,150]\n",
    "# param['max_depth'] = [2, 4, 6, 8]\n",
    "# param['max_depth'] = [5, 20, 50, 100]\n",
    "# param['max_depth'] = [2,...,15]\n",
    "\n",
    "# param_list = [(\"eta\", 0.08), (\"max_depth\", 6), (\"subsample\", 0.8), \n",
    "#               (\"colsample_bytree\", 0.8), (\"objective\", \"multi:softmax\"), \n",
    "#               (\"eval_metric\", \"merror\"), (\"alpha\", 8), (\"lambda\", 2), (\"num_class\", 10)]\n",
    "param = {}\n",
    "param['objective'] = 'multi:softmax'\n",
    "param['eta'] = 0.3\n",
    "param['num_class'] = 10\n",
    "param[\"subsample\"] = 0.8\n",
    "param[\"colsample_bytree\"] = 0.8\n",
    "param[\"eval_metric\"] = 'merror'\n",
    "param['silent'] = 1\n",
    "param['tree_method'] = 'exact'\n",
    "num_round = 5\n",
    "param['max_depth'] = 15\n",
    "print(param)\n",
    "print(num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bst = xgb.train(param, dtrain, num_round, evallist)\n",
    "\n",
    "# bst = xgb.train(param, dtrain, num_round)\n",
    "# for i in range(1):\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# arr = np.arange(train_data.shape[0])\n",
    "# np.random.shuffle(arr)\n",
    "# num_of_train = int(arr.shape[0]*0.8)\n",
    "# dtrain = xgb.DMatrix(train_data[arr[:num_of_train]], label=train_label[arr[:num_of_train]])\n",
    "# dval = xgb.DMatrix(train_data[arr[num_of_train:]], label=train_label[arr[num_of_train:]])\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_data, train_label, test_size=0.2)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dval = xgb.DMatrix(x_valid, label=y_valid)\n",
    "\n",
    "dtest = xgb.DMatrix(test_data, label=test_label)\n",
    "evallist = [(dtrain, 'train'),(dval, 'validation')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.079771\tvalidation-merror:0.1655\n",
      "Multiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation-merror hasn't improved in 5 rounds.\n",
      "[1]\ttrain-merror:0.048542\tvalidation-merror:0.147583\n",
      "[2]\ttrain-merror:0.035729\tvalidation-merror:0.1385\n",
      "[3]\ttrain-merror:0.026396\tvalidation-merror:0.133083\n",
      "[4]\ttrain-merror:0.019938\tvalidation-merror:0.12925\n",
      "Test accuracy using softmax = 0.86\n",
      "40.819803953170776  seconds\n"
     ]
    }
   ],
   "source": [
    "\n",
    "early_stopping = 5\n",
    "time1 = time.time()\n",
    "bst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=early_stopping)\n",
    "pred = bst.predict(dtest)\n",
    "time2 = time.time()\n",
    "acc_rate = np.sum(pred == test_label) / test_label.shape[0]\n",
    "print('Test accuracy using softmax = {}'.format(acc_rate))\n",
    "\n",
    "print((time2-time1),\" seconds\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/python\n",
    "# import numpy as np\n",
    "# import xgboost as xgb\n",
    "\n",
    "# ### load data in do training\n",
    "# param = {}\n",
    "# # use softmax multi-class classification\n",
    "# param['objective'] = 'multi:softmax'\n",
    "# # scale weight of positive examples\n",
    "# param['eta'] = 0.1\n",
    "# param['max_depth'] = 10\n",
    "# param['silent'] = 1\n",
    "# param['nthread'] = 6\n",
    "# param['num_class'] = 10\n",
    "# num_round = 2\n",
    "\n",
    "# xgb.cv(param, dtrain, num_round, nfold=5, metrics={'auc'}, seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
