{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost\n",
    "#https://xgboost.readthedocs.io/en/latest/python/index.html\n",
    "# https://github.com/dmlc/xgboost/blob/master/demo/multiclass_classification/train.py#L35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dtree.ipynb                t10k-labels-idx1-ubyte.gz\r\n",
      "RF.ipynb                   train-images-idx3-ubyte.gz\r\n",
      "\u001b[34m__pycache__\u001b[m\u001b[m                train-labels-idx1-ubyte.gz\r\n",
      "load_mnist.py              xgboost.ipynb\r\n",
      "t10k-images-idx3-ubyte.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_mnist import load_mnist\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "train_data, train_label = load_mnist(\"\",\"train\")\n",
    "test_data,test_label = load_mnist(\"\",\"t10k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/geyang/anaconda3/lib/python3.6/site-packages/sklearn/utils/validation.py:475: DataConversionWarning: Data with input dtype uint8 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sc = StandardScaler()\n",
    "X_main_std = sc.fit(train_data)\n",
    "\n",
    "train_data = X_main_std.transform(train_data)\n",
    "test_data = X_main_std.transform(test_data)\n",
    "\n",
    "\n",
    "# min_max_scaler=preprocessing.MinMaxScaler()  \n",
    "# min_max=min_max_scaler.fit(train_data)\n",
    "\n",
    "# train_data = min_max.transform(train_data)\n",
    "# test_data = min_max.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'objective': 'multi:softmax', 'eta': 0.3, 'num_class': 10, 'subsample': 0.8, 'colsample_bytree': 0.8, 'eval_metric': 'merror', 'silent': 1, 'max_depth': 5}\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# num_round = [2,10,50,150]\n",
    "# param['max_depth'] = [2, 4, 6, 8]\n",
    "# param['max_depth'] = [5, 20, 50, 100]\n",
    "# param['max_depth'] = [2,...,15]\n",
    "\n",
    "# param_list = [(\"eta\", 0.08), (\"max_depth\", 6), (\"subsample\", 0.8), \n",
    "#               (\"colsample_bytree\", 0.8), (\"objective\", \"multi:softmax\"), \n",
    "#               (\"eval_metric\", \"merror\"), (\"alpha\", 8), (\"lambda\", 2), (\"num_class\", 10)]\n",
    "param = {}\n",
    "param['objective'] = 'multi:softmax'\n",
    "param['eta'] = 0.3\n",
    "param['num_class'] = 10\n",
    "param[\"subsample\"] = 0.8\n",
    "param[\"colsample_bytree\"] = 0.8\n",
    "param[\"eval_metric\"] = 'merror'\n",
    "param['silent'] = 1\n",
    "\n",
    "num_round = 100\n",
    "param['max_depth'] = 5\n",
    "print(param)\n",
    "print(num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# bst = xgb.train(param, dtrain, num_round, evallist)\n",
    "\n",
    "# bst = xgb.train(param, dtrain, num_round)\n",
    "# for i in range(1):\n",
    "\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# arr = np.arange(train_data.shape[0])\n",
    "# np.random.shuffle(arr)\n",
    "# num_of_train = int(arr.shape[0]*0.8)\n",
    "# dtrain = xgb.DMatrix(train_data[arr[:num_of_train]], label=train_label[arr[:num_of_train]])\n",
    "# dval = xgb.DMatrix(train_data[arr[num_of_train:]], label=train_label[arr[num_of_train:]])\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_data, train_label, test_size=0.2)\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dval = xgb.DMatrix(x_valid, label=y_valid)\n",
    "\n",
    "dtest = xgb.DMatrix(test_data, label=test_label)\n",
    "evallist = [(dtrain, 'train'),(dval, 'validation')]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.189688\tvalidation-merror:0.202417\n",
      "Multiple eval metrics have been passed: 'validation-merror' will be used for early stopping.\n",
      "\n",
      "Will train until validation-merror hasn't improved in 5 rounds.\n",
      "[1]\ttrain-merror:0.168583\tvalidation-merror:0.182917\n",
      "[2]\ttrain-merror:0.16025\tvalidation-merror:0.172833\n",
      "[3]\ttrain-merror:0.152208\tvalidation-merror:0.168\n",
      "[4]\ttrain-merror:0.144917\tvalidation-merror:0.16125\n",
      "[5]\ttrain-merror:0.140604\tvalidation-merror:0.1565\n",
      "[6]\ttrain-merror:0.135417\tvalidation-merror:0.15475\n",
      "[7]\ttrain-merror:0.131396\tvalidation-merror:0.150917\n",
      "[8]\ttrain-merror:0.127813\tvalidation-merror:0.147917\n",
      "[9]\ttrain-merror:0.122958\tvalidation-merror:0.145417\n",
      "[10]\ttrain-merror:0.11925\tvalidation-merror:0.141167\n",
      "[11]\ttrain-merror:0.115854\tvalidation-merror:0.139167\n",
      "[12]\ttrain-merror:0.112042\tvalidation-merror:0.137917\n",
      "[13]\ttrain-merror:0.108792\tvalidation-merror:0.134917\n",
      "[14]\ttrain-merror:0.105979\tvalidation-merror:0.13275\n",
      "[15]\ttrain-merror:0.103771\tvalidation-merror:0.131833\n",
      "[16]\ttrain-merror:0.101\tvalidation-merror:0.12975\n",
      "[17]\ttrain-merror:0.097917\tvalidation-merror:0.127667\n",
      "[18]\ttrain-merror:0.095125\tvalidation-merror:0.126417\n",
      "[19]\ttrain-merror:0.092292\tvalidation-merror:0.126\n",
      "[20]\ttrain-merror:0.089938\tvalidation-merror:0.123667\n",
      "[21]\ttrain-merror:0.086938\tvalidation-merror:0.123917\n",
      "[22]\ttrain-merror:0.083771\tvalidation-merror:0.122917\n",
      "[23]\ttrain-merror:0.081771\tvalidation-merror:0.12175\n",
      "[24]\ttrain-merror:0.078979\tvalidation-merror:0.121333\n",
      "[25]\ttrain-merror:0.076833\tvalidation-merror:0.12\n",
      "[26]\ttrain-merror:0.074479\tvalidation-merror:0.1195\n",
      "[27]\ttrain-merror:0.072333\tvalidation-merror:0.119083\n",
      "[28]\ttrain-merror:0.070396\tvalidation-merror:0.11825\n",
      "[29]\ttrain-merror:0.068896\tvalidation-merror:0.118417\n",
      "[30]\ttrain-merror:0.066542\tvalidation-merror:0.116917\n",
      "[31]\ttrain-merror:0.064646\tvalidation-merror:0.116083\n",
      "[32]\ttrain-merror:0.063083\tvalidation-merror:0.115\n",
      "[33]\ttrain-merror:0.060604\tvalidation-merror:0.113583\n",
      "[34]\ttrain-merror:0.058771\tvalidation-merror:0.113583\n",
      "[35]\ttrain-merror:0.056938\tvalidation-merror:0.112917\n",
      "[36]\ttrain-merror:0.055167\tvalidation-merror:0.1125\n",
      "[37]\ttrain-merror:0.053396\tvalidation-merror:0.111417\n",
      "[38]\ttrain-merror:0.051625\tvalidation-merror:0.111333\n",
      "[39]\ttrain-merror:0.05025\tvalidation-merror:0.110833\n",
      "[40]\ttrain-merror:0.049271\tvalidation-merror:0.110167\n",
      "[41]\ttrain-merror:0.047729\tvalidation-merror:0.1085\n",
      "[42]\ttrain-merror:0.046417\tvalidation-merror:0.10725\n",
      "[43]\ttrain-merror:0.045\tvalidation-merror:0.108583\n",
      "[44]\ttrain-merror:0.043938\tvalidation-merror:0.107667\n",
      "[45]\ttrain-merror:0.042458\tvalidation-merror:0.108167\n",
      "[46]\ttrain-merror:0.041104\tvalidation-merror:0.108083\n",
      "[47]\ttrain-merror:0.039146\tvalidation-merror:0.107583\n",
      "Stopping. Best iteration:\n",
      "[42]\ttrain-merror:0.046417\tvalidation-merror:0.10725\n",
      "\n",
      "Test accuracy using softmax = 0.8819\n",
      "899.874862909317  seconds\n"
     ]
    }
   ],
   "source": [
    "time1 = time.time()\n",
    "early_stopping = 5\n",
    "bst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=early_stopping)\n",
    "pred = bst.predict(dtest)\n",
    "acc_rate = np.sum(pred == test_label) / test_label.shape[0]\n",
    "print('Test accuracy using softmax = {}'.format(acc_rate))\n",
    "time2 = time.time()\n",
    "print((time2-time1),\" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/python\n",
    "# import numpy as np\n",
    "# import xgboost as xgb\n",
    "\n",
    "# ### load data in do training\n",
    "# param = {}\n",
    "# # use softmax multi-class classification\n",
    "# param['objective'] = 'multi:softmax'\n",
    "# # scale weight of positive examples\n",
    "# param['eta'] = 0.1\n",
    "# param['max_depth'] = 10\n",
    "# param['silent'] = 1\n",
    "# param['nthread'] = 6\n",
    "# param['num_class'] = 10\n",
    "# num_round = 2\n",
    "\n",
    "# xgb.cv(param, dtrain, num_round, nfold=5, metrics={'auc'}, seed=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
