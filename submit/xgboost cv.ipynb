{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from load_mnist import load_mnist\n",
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "from sklearn.metrics import precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardization\n",
    "Determine the mean and standard deviation for each feature, then subtract the mean from each feature,divide the values by corresponding standard deviation.\n",
    "\\begin{equation}\n",
    "{x}' = \\frac{x-\\bar{x}}{\\delta }\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "train_data, train_label = load_mnist(\"\",\"train\")\n",
    "test_data,test_label = load_mnist(\"\",\"t10k\")\n",
    "\n",
    "# Do standardization on both training and test data\n",
    "sc = StandardScaler()\n",
    "X_main_std = sc.fit(train_data)\n",
    "train_data = X_main_std.transform(train_data)\n",
    "test_data = X_main_std.transform(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set common parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters for XGBoost\n",
    "param = {}\n",
    "param['objective'] = 'multi:softmax'\n",
    "param['eta'] = 0.3\n",
    "param['num_class'] = 10\n",
    "param[\"subsample\"] = 0.8\n",
    "param[\"colsample_bytree\"] = 0.8\n",
    "param[\"eval_metric\"] = 'merror'\n",
    "param['silent'] = 1\n",
    "\n",
    "# number of trees\n",
    "num_round = 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Different tree method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# different tree method. 'approx' is faster than 'exact'. gpu_exact is a GPU method\n",
    "param['tree_method'] = 'approx'\n",
    "# param['tree_method'] = 'exact'\n",
    "# param['tree_method'] = 'gpu_exact'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation (Time consuming)\n",
    "To choose appropriate max_depth, we divide the training set into 10 sections, train 10 times on it and each time use 9 sections as training data, 1 section as validation set, compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def cv_test():\n",
    "    kf = KFold(n_splits = 10)\n",
    "    accs = []\n",
    "    time1 = time.time()\n",
    "    i = 0\n",
    "    for train_index, val_index in kf.split(train_data):\n",
    "        #divide original training data into new trainig data and validation data\n",
    "        x_train = train_data[train_index]\n",
    "        y_train = train_label[train_index]\n",
    "        x_valid = train_data[val_index]\n",
    "        y_valid = train_label[val_index]\n",
    "        \n",
    "        dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "        dval = xgb.DMatrix(x_valid, label=y_valid)\n",
    "        evallist = [(dtrain, 'train'),(dval, 'validation')]\n",
    "        \n",
    "        #training\n",
    "        early_stopping = 5\n",
    "        bst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=early_stopping,verbose_eval=False)\n",
    "        \n",
    "        #predicting on validation data\n",
    "        pred = bst.predict(dval)\n",
    "        \n",
    "        acc_rate = np.sum(pred == y_valid) / y_valid.shape[0]\n",
    "        bst.__del__()\n",
    "        accs.append(acc_rate)\n",
    "        \n",
    "    time2 = time.time()\n",
    "    total_time = time2-time1\n",
    "    print(\"maxdepth is \",str(max_depth),\". Time:\",str(total_time), \"\\nAverage Score:\", sum(accs)/len(accs))\n",
    "\n",
    "    \n",
    "Maxdepth = [2,4,6,10,15]\n",
    "for depth in Maxdepth:\n",
    "    param['max_depth'] = depth\n",
    "    cv_test()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and TestÂ¶\n",
    "We found max_depth = 15 would give us best result, we used it train model, used the model for predicting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param['max_depth'] = 6\n",
    "dtest = xgb.DMatrix(test_data, label=test_label)\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_data, train_label, test_size=0.2)\n",
    "dtrain = xgb.DMatrix(x_train, label=y_train)\n",
    "dval = xgb.DMatrix(x_valid, label=y_valid)\n",
    "evallist = [(dtrain, 'train'),(dval, 'validation')]\n",
    "\n",
    "early_stopping = 5\n",
    "time1 = time.time()\n",
    "bst = xgb.train(param, dtrain, num_round, evallist, early_stopping_rounds=early_stopping)\n",
    "pred = bst.predict(dtest)\n",
    "time2 = time.time()\n",
    "acc_rate = np.sum(pred == test_label) / test_label.shape[0]\n",
    "\n",
    "print('Test accuracy using softmax = {}'.format(acc_rate))\n",
    "runtime = time2-time1\n",
    "print(runtime,\" seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion maxtrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "#         print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        pass\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.tight_layout()\n",
    "    \n",
    "# Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(pred, test_label)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "plt.figure(figsize=(8,6))\n",
    "plot_confusion_matrix(cnf_matrix, classes=[0,1,2,3,4,5,6,7,8,9],\n",
    "                      title='Confusion matrix, without normalization')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision, Recall, F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, f1, size = precision_recall_fscore_support(test_label,pred)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(f1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
